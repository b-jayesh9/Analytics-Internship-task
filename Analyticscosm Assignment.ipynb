{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1. What libraries will you import and how?\n",
    "\n",
    "# Ans : Will import Matplotlib and Seaborn for data visualization,\n",
    "#       pandas,numpy and random for data manipulation, \n",
    "#       and scikit learn for computation.\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# we can import more scikit learn models but I'm just including these two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How will you read the dataset called train.csv available in mydata folder if you are to read it to dataframe using pandas?\n",
    "\n",
    "# Ans : Using the pd.read_csv command of pandas\n",
    "\n",
    "train_df = pd.read_csv('../mydata/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3. How will you select top 10 rows from the data?\n",
    "\n",
    "# Ans : Using head() command of pandas\n",
    "\n",
    "train_df.head(10) \n",
    "\n",
    "# here 10 is the number of rows to be selected. You can specify any number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q4. How will you get summary of numerical fields?\n",
    "\n",
    "# Ans : Using describe() feature of pandas\n",
    "\n",
    "train_df.describe()\n",
    "\n",
    "# here describe has more components namely percentiles,include and exclude which have different function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q5. How will you print the frequency table for the data?\n",
    "\n",
    "# Ans : Using 'value_counts' function of pandas we can do this easily.\n",
    "\n",
    "df = pd.value_counts(df.NameofColumn).to_frame().reset_index()\n",
    "\n",
    "#this will give the frequency table as requested.\n",
    "# Here name of column may include marital status, previous purchase status, time after previous purchase, education, Loan Amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q6. How will you study distribution of various variables?\n",
    "\n",
    "# Ans : This has many methods and generally depends on the type of problem. But generally we use 'groupby' to understand the \n",
    "#       correlation, if any.\n",
    "\n",
    "df.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False)\n",
    "\n",
    "#This is the default syntax of groupby.\n",
    "\n",
    "#More examples:\n",
    "     data.groupby(func, axis=0).mean() # this will calculate the mean of the whole data\n",
    "     data.groupby(['col1', 'col2']).mean() # will calculate mean of selected columns through hierarchial index\n",
    "\n",
    "#If the data has datetime-like index, we can also use 'resample'\n",
    "     \n",
    "     DataFrame.resample(rule,label=None) # Used to study time series distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q7. How will you plot the target variable against each dependent variable?\n",
    "\n",
    "# Ans : This can be done using many methods but the most common of them is using pairplot of seaborn.\n",
    "\n",
    "pp = sns.pairplot(data=train_df,\n",
    "                  y_vars=['purchase'],\n",
    "                  x_vars=['marital status','previous purchase status','time after previous purchase','education', 'Loan Amount'])\n",
    "\n",
    "#You can further modify it as per requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explaination using words:\n",
    "# Q1. What environment will you use?\n",
    "\n",
    "'''I will use an Ipython environment like Jupyter running through Ananconda support since it contains mostly all the \n",
    "required features that a Data Scientist needs like pandas,matplotlib,scikit learn, seaborn etc.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q2. How we can use the simple method of plotting two variables side by side to see which variable is the best predictor?  \n",
    "\n",
    "'''I didn't fully understand this question but I belive that you're asking about Multi-Linear Regression in Python, which \n",
    "is a predictive model that compares 1 dependent variable with 2 or more independent variables. We can use a scatter plot to \n",
    "do the task. If you're talking about multivariate analysis, we can use A Matrix Scatterplot, with different colors according\n",
    "to their variables or can use a Profile Plot, or a HeatMap depending upon the type of question.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
